{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87310139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(directory, output_directory, size=(128, 128)):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Open the image file\n",
    "            with Image.open(os.path.join(directory, filename)) as img:\n",
    "                # Resize the image\n",
    "                resized_img = img.resize(size)\n",
    "                \n",
    "                # Save the resized image to the output directory\n",
    "                resized_img.save(os.path.join(output_directory, filename), format=\"JPEG\")\n",
    "\n",
    "# Example usage\n",
    "input_directory_cats = 'reference/cats'\n",
    "input_directory_dogs = 'reference/dogs'\n",
    "output_directory_cats_resized = 'reference/cats_resized'\n",
    "output_directory_dogs_resized = 'reference/dogs_resized'\n",
    "\n",
    "# Resize images in the \"cats\" directory\n",
    "resize_images(input_directory_cats, output_directory_cats_resized)\n",
    "\n",
    "# Resize images in the \"dogs\" directory\n",
    "resize_images(input_directory_dogs, output_directory_dogs_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a7fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\B365M21\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\B365M21\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\B365M21\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D-1 (Conv2D)           (None, 128, 128, 32)      2432      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " MaxPool-1 (MaxPooling2D)    (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " Conv2D-2 (Conv2D)           (None, 64, 64, 64)        51264     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " MaxPool-2 (MaxPooling2D)    (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " Conv2D-3 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " MaxPool-3 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " Conv2D-4 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " MaxPool-4 (MaxPooling2D)    (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8192)              134225920 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              8389632   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143695682 (548.16 MB)\n",
      "Trainable params: 143695682 (548.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, MaxPooling2D\n",
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        batch_input_shape=(None,128,128,3),\n",
    "        filters = 32,\n",
    "        kernel_size=(5,5),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name=\"Conv2D-1\",\n",
    "    ),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        name=\"MaxPool-1\",\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size=(5,5),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name=\"Conv2D-2\",\n",
    "    ),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        name=\"MaxPool-2\",\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernel_size=(5,5),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name=\"Conv2D-3\",\n",
    "    ),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        name=\"MaxPool-3\",\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernel_size=(5,5),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        name=\"Conv2D-4\",\n",
    "    ),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        name=\"MaxPool-4\",\n",
    "    ),\n",
    "    Flatten(),\n",
    "    Dense(8192),\n",
    "    Activation('relu'),\n",
    "    Dense(1024),\n",
    "    Activation('relu'),\n",
    "    Dense(2),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d518eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5089 - accuracy: 0.7125 - val_loss: 0.6645 - val_accuracy: 0.7000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6292 - accuracy: 0.6375 - val_loss: 0.7765 - val_accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6044 - accuracy: 0.6250 - val_loss: 0.7190 - val_accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.4839 - accuracy: 0.7625 - val_loss: 0.6432 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4452 - accuracy: 0.7625 - val_loss: 0.7052 - val_accuracy: 0.6500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4174 - accuracy: 0.7875 - val_loss: 0.7180 - val_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3182 - accuracy: 0.8875 - val_loss: 0.6993 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2945 - accuracy: 0.8875 - val_loss: 0.7881 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2752 - accuracy: 0.8750 - val_loss: 1.0153 - val_accuracy: 0.6000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1776 - accuracy: 0.9125 - val_loss: 1.3886 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set the paths to your dataset\n",
    "cats_dir = 'reference/cats'\n",
    "dogs_dir = 'reference/dogs'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(directory, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((128, 128))  # Resize images to (128, 128)\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load and preprocess cat images\n",
    "cat_images, cat_labels = load_and_preprocess_images(cats_dir, label=0)\n",
    "\n",
    "# Load and preprocess dog images\n",
    "dog_images, dog_labels = load_and_preprocess_images(dogs_dir, label=1)\n",
    "\n",
    "# Combine cat and dog data\n",
    "images = np.concatenate([cat_images, dog_images], axis=0)\n",
    "labels = np.concatenate([cat_labels, dog_labels], axis=0)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "labels_one_hot = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Shuffle the data\n",
    "images, labels_one_hot = shuffle(images, labels_one_hot, random_state=42)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and compile the model\n",
    "# (Use the model definition you provided earlier)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train,y_train, epochs=10, batch_size=32 , validation_data=(X_val, y_val))\n",
    "\n",
    "model.save_weights('HW4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f7a6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 100ms/step\n",
      "AUROC: 0.5159375\n",
      "Confusion Matrix:\n",
      "[[19 21]\n",
      " [18 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Assuming binary classification, extract the probability of the positive class\n",
    "positive_class_probabilities = predictions[:, 1]\n",
    "\n",
    "# Assuming binary classification, create binary labels (0 or 1) based on a threshold\n",
    "threshold = 0.5  # Adjust this threshold as needed\n",
    "predicted_labels = (positive_class_probabilities > threshold).astype(int)\n",
    "\n",
    "# Assuming binary classification, create true binary labels for the test set\n",
    "# Adjust this based on your actual labeling in the test set\n",
    "true_labels = np.array([0] * (len(X_train) // 2) + [1] * (len(X_train) // 2))\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(true_labels, positive_class_probabilities)\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Create and plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa629aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "[0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0]\n",
      "AUROC: 0.45999999999999996\n",
      "Confusion Matrix:\n",
      "[[6 4]\n",
      " [7 3]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set the path to your test directory\n",
    "test_dir = 'test'\n",
    "\n",
    "# Load the trained model\n",
    "# Make sure to adjust 'path/to/your/model.h5' to the actual path of your saved model\n",
    "model.load_weights('HW4.h5')\n",
    "\n",
    "# Function to load and preprocess test images\n",
    "def load_and_preprocess_test_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((128 , 128))\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "            images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load and preprocess test images\n",
    "X_test = load_and_preprocess_test_images(test_dir)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# # Assuming binary classification, extract the probability of the positive class\n",
    "positive_class_probabilities = predictions[:, 1]\n",
    "\n",
    "# # Assuming binary classification, create binary labels (0 or 1) based on a threshold\n",
    "threshold = 0.5  # Adjust this threshold as needed\n",
    "predicted_labels = (positive_class_probabilities > threshold).astype(int)\n",
    "print(predicted_labels)\n",
    "# # Assuming binary classification, create true binary labels for the test set\n",
    "# # Adjust this based on your actual labeling in the test set\n",
    "true_labels = np.array([0] * (len(X_test) // 2) + [1] * (len(X_test) // 2))\n",
    "\n",
    "# # Calculate AUROC\n",
    "auroc = roc_auc_score(true_labels, positive_class_probabilities)\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Create and plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5663bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae7667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
